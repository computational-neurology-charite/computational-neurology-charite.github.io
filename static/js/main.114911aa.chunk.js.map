{"version":3,"sources":["components/Header.js","components/Projects.js","components/Team.js","components/Alumni.js","utils/sanitizeLatex.js","components/Publications.js","components/Footer.js","components/CompetitionAnouncement.js","components/Competition.js","App.js","reportWebVitals.js","index.js"],"names":["Header","React","createElement","Fragment","className","RouterLink","to","style","textDecoration","color","align","Link","smooth","duration","projectsData","id","title","shortDescription","fullDescription","image","href","ProjectCard","_ref","project","isExpanded","onClick","src","alt","Projects","expandedId","setExpandedId","useState","map","key","handleCardClick","membersData","name","role","desc","TeamCard","member","Team","alumniNames","Alumni","n","sanitizeLatex","text","sanitized","replacements","Object","keys","forEach","regex","RegExp","replace","accentedReplacements","Publications","publications","setPublications","expandedPub","setExpandedPub","searchTerm","setSearchTerm","useEffect","async","response","fetch","Date","now","bibtexText","formatted","bibtexParse","toJSON","entry","citationKey","entryTags","authors","author","journal","book","booktitle","year","doi","url","abstract","entryType","publisher","volume","pages","error","console","fetchAndParseBibTeX","publicationsByYear","reduce","acc","pub","push","sortedYears","sort","a","b","handleExpand","prev","marginBottom","marginTop","target","rel","Footer","getFullYear","CompetitionAnouncement","Competition","App","Router","Routes","Route","path","element","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","createRoot","document","getElementById","render","StrictMode"],"mappings":"udA6BeA,MAzBf,WACE,OACEC,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,cACED,IAAAC,cAAA,OAAKE,UAAU,kBACbH,IAAAC,cAACG,IAAU,CAACC,GAAG,IAAIC,MAAO,CAAEC,eAAgB,OAAQC,MAAO,YACzDR,IAAAC,cAAA,MAAIQ,MAAM,UAAS,8BAKzBT,IAAAC,cAAA,WACED,IAAAC,cAACS,OAAI,CAACL,GAAG,OAAOM,QAAQ,EAAMC,SAAU,KAAK,QAC7CZ,IAAAC,cAACS,OAAI,CAACL,GAAG,WAAWM,QAAQ,EAAMC,SAAU,KAAK,YACjDZ,IAAAC,cAACS,OAAI,CAACL,GAAG,OAAOM,QAAQ,EAAMC,SAAU,KAAK,QAC7CZ,IAAAC,cAACS,OAAI,CAACL,GAAG,eAAeM,QAAQ,EAAMC,SAAU,KAAK,gBACrDZ,IAAAC,cAACS,OAAI,CAACL,GAAG,SAASM,QAAQ,EAAMC,SAAU,KAAK,WAG/CZ,IAAAC,cAACG,IAAU,CAACC,GAAG,oBAAmB,sB,MCpB1C,MAAMQ,EAAe,CACnB,CACEC,GAAI,EACJC,MAAO,qCACPC,iBAAkB,6DAClBC,gBAAiB,0kCACjBC,MAAO,2BAET,CACEJ,GAAI,EACJC,MAAO,sCACPC,iBAAkB,6DAClBC,gBAAiB,oSACpBC,MAAO,+BAEL,CACCJ,GAAI,EACJC,MAAO,sCACPC,iBAAkB,2DAClBC,gBAAiB,4hCACjBC,MAAO,2BAGT,CACEJ,GAAI,EACJC,MAAO,WACPC,iBAAkB,wDAClBC,gBAAiB,2qBACjBC,MAAO,sCAET,CACEJ,GAAI,EACJC,MAAO,YACPC,iBAAkB,kGAClBC,gBAAiBjB,IAAAC,cAAA,WACjBD,IAAAC,cAAA,KAAGkB,KAAK,uBAAsB,aAAa,syBAI3CD,MAAO,wBAET,CACEJ,GAAI,EACJC,MAAO,SACPC,iBAAkB,4CAClBC,gBACAjB,IAAAC,cAAA,WACFD,IAAAC,cAAA,KAAGkB,KAAK,yBAAwB,UAAU,ojBAExCD,MAAO,8BAEX,CACIJ,GAAI,EACJC,MAAO,kBACPC,iBAAkB,SAClBC,gBAAiB,qgBACjBC,MAAO,2BAkBX,SAASE,EAAWC,GAAoC,IAAnC,QAAEC,EAAO,WAAEC,EAAU,QAAEC,GAASH,EACnD,OACErB,IAAAC,cAAA,OAAKE,UAAW,iBAAgBoB,EAAa,WAAa,IAAMC,QAASA,GACrED,EAA2D,KAAhDvB,IAAAC,cAAA,OAAKwB,IAAKH,EAAQJ,MAAOQ,IAAKJ,EAAQP,QACnDf,IAAAC,cAAA,UAAKqB,EAAQP,OACbf,IAAAC,cAAA,SAAIsB,EAAaD,EAAQL,gBAAkBK,EAAQN,kBACjDO,EAAsD,KAA3CvB,IAAAC,cAAA,QAAME,UAAU,aAAY,YA6BhCwB,MAxBf,WACE,MAAOC,EAAYC,GAAiBC,mBAAS,MAM7C,OACE9B,IAAAC,cAAA,WAASa,GAAG,YACVd,IAAAC,cAAA,MAAIE,UAAU,iBAAgB,YAC9BH,IAAAC,cAAA,OAAKE,UAAU,sBACZU,EAAakB,IAAKT,GACjBtB,IAAAC,cAACmB,EAAW,CACVY,IAAKV,EAAQR,GACbQ,QAASA,EACTC,WAAYK,IAAeN,EAAQR,GACnCU,QAASA,KAAMS,OAbAnB,EAagBQ,EAAQR,QAZ/Ce,EAAcD,IAAed,EAAK,KAAOA,GADlBA,a,MCzF3B,MAAMoB,EAAc,CAClB,CAAEC,KAAM,mBACNC,KAAM,yBACNlB,MAAO,4BACPmB,KAAM,IAOR,CAAEF,KAAM,kBACNC,KAAM,cACNlB,MAAO,wBACPmB,KAAM,IAER,CAAEF,KAAM,gBACNC,KAAM,UACNlB,MAAO,yBACPmB,KAAM,IAER,CAAEF,KAAM,mBACNC,KAAM,cACNlB,MAAO,2BACPmB,KAAM,+WAER,CAAEF,KAAM,iBACNC,KAAM,iBACNlB,MAAO,8BACPmB,KAAM,mfAER,CAAEF,KAAM,aACNC,KAAM,iBACNlB,MAAO,wBACPmB,KAAMrC,IAAAC,cAAA,WAAK,2kBAAwkBD,IAAAC,cAAA,KAAGkB,KAAK,uBAAsB,uBAAwB,oDAK3oB,CAAEgB,KAAM,gBACNC,KAAM,kBACNlB,MAAO,yBACPmB,KAAM,oXAER,CAAEF,KAAM,cACNC,KAAM,cACNlB,MAAO,yBACPmB,KAAM,IAER,CAAEF,KAAM,sBACNC,KAAM,iBACNlB,MAAO,wBACPmB,KAAM,IAER,CAAEF,KAAM,uBACNC,KAAM,iBACNlB,MAAO,qCACPmB,KAAM,IAER,CAAEF,KAAM,kBACNC,KAAM,cACNlB,MAAO,2BACPmB,KAAM,qUAER,CAAEF,KAAM,iBACNC,KAAM,UACNlB,MAAO,wBACPmB,KAAM,+bAER,CAAEF,KAAM,iBACNC,KAAM,iBACNlB,MAAO,0BACPmB,KAAM,IAER,CAAEF,KAAM,aACNC,KAAM,cACNlB,MAAO,yBACPmB,KAAM,kjBAER,CAAEF,KAAM,cACNC,KAAM,iBACNlB,MAAO,sBACPmB,KAAM,ggBAER,CAAEF,KAAM,iBACNC,KAAM,iBACNlB,MAAO,0BACPmB,KAAM,KAOV,SAASC,EAAQjB,GAAmC,IAAlC,OAAEkB,EAAM,WAAEhB,EAAU,QAAEC,GAASH,EAC/C,OACErB,IAAAC,cAAA,OAAKE,UAAW,cAAaoB,EAAa,WAAa,IAAMC,QAASA,GACpExB,IAAAC,cAAA,OAAKwB,IAAKc,EAAOrB,MAAOQ,IAAKa,EAAOJ,OACpCnC,IAAAC,cAAA,UAAKsC,EAAOJ,MACZnC,IAAAC,cAAA,SAAIsC,EAAOH,MACXpC,IAAAC,cAAA,SAAIsB,EAAagB,EAAOF,KAAwB,KAAhBE,EAAOF,KAAc,KAAOrC,IAAAC,cAAA,QAAME,UAAW,aAAa,aA4JjFqC,MAtJf,WACE,MAAOZ,EAAYC,GAAiBC,mBAAS,MAM7C,OACE9B,IAAAC,cAAA,OAAKE,UAAU,0BACfH,IAAAC,cAAA,WAASa,GAAG,QACVd,IAAAC,cAAA,OAAKE,UAAU,4BACfH,IAAAC,cAAA,MAAIE,UAAU,4BAA2B,QACvCH,IAAAC,cAAA,OAAKE,UAAU,kBACd+B,EAAYH,IAAKQ,GAChBvC,IAAAC,cAACqC,EAAQ,CACPN,IAAKO,EAAOJ,KACZI,OAAQA,EACRhB,WAAYK,IAAeW,EAAOJ,KAClCX,QAASA,KAAMS,OAfAnB,EAegByB,EAAOJ,UAd9CN,EAAcD,IAAed,EAAK,KAAOA,GADlBA,e,MC5G3B,MAAM2B,EAAc,CAClB,gBACA,gBACA,iBACA,aACA,sBACA,uBACA,oBACA,eACA,mBAGa,SAASC,IACtB,OACE1C,IAAAC,cAAA,WAASa,GAAG,UACVd,IAAAC,cAAA,MAAIE,UAAU,iBAAgB,UAE9BH,IAAAC,cAAA,OAAKE,UAAU,eACbH,IAAAC,cAAA,OACEwB,IAAI,0BACJC,IAAI,WACJvB,UAAU,gBAGZH,IAAAC,cAAA,MAAIE,UAAU,eACXsC,EAAYV,IAAKY,GAChB3C,IAAAC,cAAA,MAAI+B,IAAKW,GAAIA,O,2BC3BlB,SAASC,EAAcC,GAC1B,IAAKA,EAAM,MAAO,GAElB,IAAIC,EAAYD,EAGhB,MAAME,EAAe,CACnB,IAAM,IACN,MAAO,IACP,MAAO,IACP,MAAO,IACP,MAAO,IACP,MAAO,IACP,MAAO,IACP,QAAS,IACT,QAAS,IACT,YAAa,GACb,YAAa,GACb,YAAa,GACb,IAAK,GACL,IAAK,GACL,MAAO,KAGTC,OAAOC,KAAKF,GAAcG,QAASlB,IACjC,MAAMmB,EAAQ,IAAIC,OAAOpB,EAAK,KAC9Bc,EAAYA,EAAUO,QAAQF,EAAOJ,EAAaf,MAIpD,MAAMsB,EAAuB,CAC3B,SAAU,OACV,SAAU,OACV,SAAU,OACV,SAAU,OACV,SAAU,IACV,OAAQ,OACR,OAAQ,OACR,OAAQ,SACR,OAAQ,OACR,OAAQ,KAYV,OARAN,OAAOC,KAAKK,GAAsBJ,QAASlB,IACzC,MAAMmB,EAAQ,IAAIC,OAAOpB,EAAK,KAC9Bc,EAAYA,EAAUO,QAAQF,EAAOG,EAAqBtB,MAI5Dc,EAAYA,EAAUO,QAAQ,0BAA2B,MAElDP,ECkDIS,MAnGf,WACE,MAAOC,EAAcC,GAAmB3B,mBAAS,KAC1C4B,EAAaC,GAAkB7B,mBAAS,OACxC8B,EAAYC,GAAiB/B,mBAAS,IAE7CgC,oBAAU,KACoBC,WAC1B,IACE,MAAMC,QAAiBC,MAAM,wBAAwBC,KAAKC,OACpDC,QAAmBJ,EAASnB,OAE5BwB,EADSC,IAAYC,OAAOH,GACTrC,IAAIyC,IAAK,CAChC1D,GAAI0D,EAAMC,YACV1D,MAAO6B,EAAc4B,EAAME,UAAU3D,OACrC4D,QAASH,EAAME,UAAUE,OACzBC,QAASjC,EAAc4B,EAAME,UAAUG,SAC/CC,KAAMlC,EAAc4B,EAAME,UAAUK,WAC5BC,KAAMR,EAAME,UAAUM,KACtBC,IAAKT,EAAME,UAAUO,IACrBC,IAAKV,EAAME,UAAUQ,IACrBC,SAAUvC,EAAc4B,EAAME,UAAUS,UACxCC,UAAWZ,EAAMY,UACvBC,UAAWb,EAAME,UAAUW,UAC3BC,OAAQd,EAAME,UAAUY,OACxBC,MAAOf,EAAME,UAAUa,SAKnB9B,EAAgBY,GAChB,MAAOmB,GACPC,QAAQD,MAAM,yCAA0CA,KAI5DE,IACC,IAIH,MAAMC,EAAqBnC,EAAaoC,OAAO,CAACC,EAAKC,KACnD,MAAMd,EAAOc,EAAId,MAAQ,eAKzB,OAJKa,EAAIb,KACPa,EAAIb,GAAQ,IAEda,EAAIb,GAAMe,KAAKD,GACRD,GACN,IAGGG,EAAchD,OAAOC,KAAK0C,GAAoBM,KAAK,CAACC,EAAGC,IAAMA,EAAID,GAMvE,OACElG,IAAAC,cAAA,WAASa,GAAG,gBACVd,IAAAC,cAAA,MAAIE,UAAU,iBAAgB,gBAC7B6F,EAAYjE,IAAIiD,GACfhF,IAAAC,cAAA,OAAK+B,IAAKgD,EAAM7E,UAAU,gBACxBH,IAAAC,cAAA,UAAK+E,GACLhF,IAAAC,cAAA,OAAKE,UAAU,kBACZwF,EAAmBX,GAAMjD,IAAI+D,GAC5B9F,IAAAC,cAAA,OACE+B,IAAK8D,EAAIhF,GACTX,UAAW,qBAAoBuD,IAAgBoC,EAAIhF,GAAK,WAAa,IACrEU,QAASA,KAAM4E,OAfPtF,EAeoBgF,EAAIhF,QAd5C6C,EAAe0C,GAASA,IAASvF,EAAK,KAAOA,GADzBA,QAiBRd,IAAAC,cAAA,UAAK6F,EAAI/E,OACTf,IAAAC,cAAA,KAAGK,MAAO,CAACE,MAAM,OAAQ8F,aAAa,OAAQC,UAAU,SAAUT,EAAInB,SACtE3E,IAAAC,cAAA,SAAGD,IAAAC,cAAA,SAAI6F,EAAIjB,SAAW,aACtB7E,IAAAC,cAAA,QAAME,UAAU,aAAauD,IAAgBoC,EAAIhF,GAAK,GAAK,WAC1D4C,IAAgBoC,EAAIhF,IACnBd,IAAAC,cAAAD,IAAAE,SAAA,KACG4F,EAAIX,UACHnF,IAAAC,cAAA,SAAGD,IAAAC,cAAA,cAAQ,aAAkB,IAAE6F,EAAIX,UAEpCW,EAAIb,KACHjF,IAAAC,cAAA,SACED,IAAAC,cAAA,cAAQ,QAAa,IAACD,IAAAC,cAAA,KAAGkB,KAAM,mBAAmB2E,EAAIb,IAAOuB,OAAO,SAASC,IAAI,uBAAuBX,EAAIb,MAG/Ga,EAAIZ,KACHlF,IAAAC,cAAA,SACED,IAAAC,cAAA,cAAQ,QAAa,IAACD,IAAAC,cAAA,KAAGkB,KAAM2E,EAAIZ,IAAKsB,OAAO,SAASC,IAAI,uBAAsB,6BCvE3FC,MAjBf,WACE,OACE1G,IAAAC,cAAA,OAAKa,GAAG,UACRd,IAAAC,cAAA,cACED,IAAAC,cAAA,SAAG,WACQ,IACTD,IAAAC,cAAA,KAAGkB,KAAK,6CAA4C,0CAItDnB,IAAAC,cAAA,SAAG,SAAQ,IAAIiE,MAAOyC,cAAc,8C,oCCR3B,SAASC,IACtB,OACE5G,IAAAC,cAAA,WAASa,GAAG,4BACVd,IAAAC,cAAA,MAAIE,UAAU,iBAAgB,kCAE9BH,IAAAC,cAAA,OAAKE,UAAU,uBACbH,IAAAC,cAAA,SAAG,2SAKPD,IAAAC,cAACS,IAAI,CAACL,GAAG,mBAAmBF,UAAU,sBAAqB,a,MCZhD,SAAS0G,IACtB,OACE7G,IAAAC,cAAA,WAASa,GAAG,eACVd,IAAAC,cAAA,MAAIE,UAAU,iBAAgB,kDAE9BH,IAAAC,cAAA,OAAKE,UAAU,qBACbH,IAAAC,cAAA,SAAG,uBACmBD,IAAAC,cAAA,cAAQD,IAAAC,cAAA,KAAGkB,KAAM,qCAAqC,gHAAyH,uKAIvMnB,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,aACJD,IAAAC,cAAA,OAAKE,UAAU,YACbH,IAAAC,cAAA,OAAKE,UAAU,KAAI,qBAAuBH,IAAAC,cAAA,OAAKE,UAAU,KAAI,qBAC7DH,IAAAC,cAAA,OAAKE,UAAU,KAAI,qBAAuBH,IAAAC,cAAA,OAAKE,UAAU,KAAI,0CAC7DH,IAAAC,cAAA,OAAKE,UAAU,KAAI,0BAAuBH,IAAAC,cAAA,OAAKE,UAAU,KAAI,kEAIjEH,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,SAAG,k7BAKLD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,aACJD,IAAAC,cAAA,SAAG,wFACoFD,IAAAC,cAAA,cAAQ,0BAA+B,skBAIhID,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,oBACJD,IAAAC,cAAA,SAAG,u+BAKAD,IAAAC,cAAA,OAAKE,UAAU,oBACxBH,IAAAC,cAAA,UAAI,iBACJD,IAAAC,cAAA,SAAG,2fAGHD,IAAAC,cAAA,SAAG,wDACDD,IAAAC,cAAA,YAAM,SAAO,IAAI,KAAG,IAAI,IAAE,IAAI,UAAQ,KACtCD,IAAAC,cAAA,SAAG,SAAMD,IAAAC,cAAA,YAAM,MAAS,QAAKD,IAAAC,cAAA,YAAM,WAAc,0EAAuED,IAAAC,cAAA,YAAM,MAAS,iEAGzID,IAAAC,cAAA,OAAKE,UAAU,aACPH,IAAAC,cAAA,WAAKD,IAAAC,cAAA,YAAO,gWActBD,IAAAC,cAAA,SAAG,qDACKD,IAAAC,cAAA,OAAKE,UAAU,aACbH,IAAAC,cAAA,WAAKD,IAAAC,cAAA,YAAO,yJAahBD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,eACJD,IAAAC,cAAA,SAAG,ggBAMPD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,uBACJD,IAAAC,cAAA,SAAG,qXAEHD,IAAAC,cAAA,UACED,IAAAC,cAAA,UAAID,IAAAC,cAAA,cAAQ,eAAoB,oBAChCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,cAAQ,eAAoB,oBAChCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,cAAQ,aAAkB,oBAC9BD,IAAAC,cAAA,UAAID,IAAAC,cAAA,cAAQ,YAAiB,uEAK/BD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,SAAG,qRAOLD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,UACJD,IAAAC,cAAA,SAAG,mKACHD,IAAAC,cAAA,MAAIE,UAAU,UACZH,IAAAC,cAAA,UAAID,IAAAC,cAAA,cAAQ,OAAY,WACxBD,IAAAC,cAAA,UAAID,IAAAC,cAAA,cAAQ,OAAY,YAE1BD,IAAAC,cAAA,SAAG,8QAGHD,IAAAC,cAAA,SAAG,+NAMLD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,SAAG,+QAGmFD,IAAAC,cAAA,KAAGkB,KAAK,6CAA4C,wCAK5InB,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,mBACJD,IAAAC,cAAA,SAAG,+FAGLD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,yBAA0B,obACmZD,IAAAC,cAAA,KAAGkB,KAAK,qCAAoC,sCAAsC,IACngBnB,IAAAC,cAAA,SAAGD,IAAAC,cAAA,cAAQ,yBACXD,IAAAC,cAAA,SAAG,oFACHD,IAAAC,cAAA,OAAKE,UAAU,aACbH,IAAAC,cAAA,WAAKD,IAAAC,cAAA,YAAO,uEAKdD,IAAAC,cAAA,SAAG,SACKD,IAAAC,cAAA,YAAM,SAAY,QAAKD,IAAAC,cAAA,YAAM,UAAa,iGAIpDD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,sBACJD,IAAAC,cAAA,SAAG,2VAKLD,IAAAC,cAAA,OAAKE,UAAU,oBACbH,IAAAC,cAAA,UAAI,mBAOJD,IAAAC,cAAA,KAAGE,UAAU,cAAa,grBAU5BH,IAAAC,cAAA,KACEkB,KAAK,+IACLqF,OAAO,SACPC,IAAI,sBACJtG,UAAU,sBACX,qBAIDH,IAAAC,cAAA,OAAKE,UAAU,QACbH,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,UACED,IAAAC,cAAA,UAAI,kMAGJD,IAAAC,cAAA,UAAI,qRCtJC6G,MArCf,WACE,OACE9G,IAAAC,cAAC8G,IAAM,KACL/G,IAAAC,cAAA,OAAKE,UAAU,OACbH,IAAAC,cAACF,EAAM,MAUfC,IAAAC,cAAC+G,IAAM,KACLhH,IAAAC,cAACgH,IAAK,CACJC,KAAK,IACLC,QACEnH,IAAAC,cAAA,YAEED,IAAAC,cAAC2G,EAAsB,MACvB5G,IAAAC,cAAC0B,EAAQ,MACT3B,IAAAC,cAACuC,EAAI,MACLxC,IAAAC,cAACyC,EAAM,MACP1C,IAAAC,cAACsD,EAAY,SAIjBvD,IAAAC,cAACgH,IAAK,CAACC,KAAK,mBAAmBC,QAASnH,IAAAC,cAAC4G,EAAW,SAGhD7G,IAAAC,cAACyG,EAAM,SCjCAU,MAZSC,IAClBA,GAAeA,aAAuBC,UACxC,6BAAqBC,KAAKlG,IAAkD,IAAjD,OAAEmG,EAAM,OAAEC,EAAM,OAAEC,EAAM,OAAEC,EAAM,QAAEC,GAASvG,EACpEmG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,M,MCADQ,IAASC,WAAWC,SAASC,eAAe,SACpDC,OACHjI,IAAAC,cAACD,IAAMkI,WAAU,KACflI,IAAAC,cAAC6G,EAAG,QAORM,M","file":"static/js/main.114911aa.chunk.js","sourcesContent":["import React from \"react\";\r\nimport { Link as RouterLink } from \"react-router-dom\";\r\nimport { Link } from \"react-scroll\";\r\n\r\nfunction Header() {\r\n  return (\r\n    <>\r\n      <header>\r\n        <div className=\"header-content\">\r\n          <RouterLink to=\"/\" style={{ textDecoration: \"none\", color: \"inherit\" }}>\r\n            <h1 align=\"center\">Computational Neurology</h1>\r\n          </RouterLink>\r\n        </div>\r\n      </header>\r\n\r\n      <nav>\r\n        <Link to=\"home\" smooth={true} duration={500}>News</Link>\r\n        <Link to=\"projects\" smooth={true} duration={500}>Projects</Link>\r\n        <Link to=\"team\" smooth={true} duration={500}>Team</Link>\r\n        <Link to=\"publications\" smooth={true} duration={500}>Publications</Link>\r\n        <Link to=\"footer\" smooth={true} duration={500}>Contact</Link>\r\n\r\n        {/* Competition is a separate page → use router link */}\r\n        <RouterLink to=\"/video_challenge\">Video Challenge</RouterLink>\r\n      </nav>\r\n    </>\r\n  );\r\n}\r\n\r\nexport default Header;\r\n\r\n","import React, { useState } from 'react';\r\nimport './Projects.css';\r\n\r\nconst projectsData = [\r\n  {\r\n    id: 1,\r\n    title: \"Computational Inpatient Monitoring\",\r\n    shortDescription: \"Predicting patient outcomes using routinely collected data\",\r\n    fullDescription: \"The increasing availability of multimodal and continuous 'physiomes' of neurological patients through digital neuromonitoring, new sensor and wearable technologies paired with advanced data analytics offer opportunities for a fundamental transformation in neurology. For inpatient monitoring in intensive care, stroke medicine and epilepsy computational neurology provides vast opportunities for the development of predictive diagnostic methods for specific and time-critical therapies. By leveraging cutting-edge machine learning techniques, our team aims to transform the raw datasets into actionable intelligence, improving the accuracy, efficiency, and scalability of diagnostic processes. Our work focuses on automating the analysis of biosignals and other clinical data to enhance real-time decision-making, reduce the burden on healthcare professionals, and streamline hospital workflows. By seamlessly integrating AI models into clinical environments, we seek to drive innovation in patient care, ultimately improving outcomes and paving the way for a more data-driven healthcare future.\",\r\n    image: \"/images/project_dwc.png\"\r\n  },\r\n  {\r\n    id: 2,\r\n    title: \"Computational Ambulatory Monitoring\",\r\n    shortDescription: \"Predicting patient outcomes using routinely collected data\",\r\n    fullDescription: \"Enabled by new, wearable sensors and computational analysis, objective methods for continuous, longitudinal monitoring and risk assessments provide opportunities for a fundamental medical transformation towards personalized, proactive and time-critical therapies in the outpatient setting.\",\r\n\timage: \"/images/Fig_Wearable_DL.jpg\"\r\n  },\r\n   {\r\n    id: 3,\r\n    title: \"Critical Dynamics in Brain Networks\",\r\n    shortDescription: \"Criticality as the optimal set-point of network dynamics\",\r\n    fullDescription: \"The brain's ability to process and integrate information across spatial and temporal domains is central to intact cognitive function. Physics and information theory have provided a framework describing an optimal state of information processing. This critical state, poised at the phase transition between chaotic and ceasing neuronal activity, is characterized by an equilibrium between excitation and inhibition in the neuronal network. When a network of neurons operates near a critical phase transition point, a range of information processing functions, including information transmission, integration, storage, dynamic range, and sensitivity to inputs, are optimized simultaneously. While criticality provides a precise framework linking network structure to dynamics, its central claim, that critical dynamics predicts optimal network and thus cognitive function in humans, has not been proven yet. To try to fill this gap by investigating multi-model cortical measurements, e.g., MRI and iEEG, together with cognitive performance evaluation.\",\r\n    image: \"/images/criticality.jpg\"\r\n  },\r\n  \r\n  {\r\n    id: 4,\r\n    title: \"Neuro-AI\",\r\n    shortDescription: \"Critical dynamics in artificial intelligence networks\",\r\n    fullDescription: \"Deep Neural Networks (DNNs) have revolutionized numerous fields, yet their training and design remain challenging due to vast parameter spaces and limited theoretical understanding. We here aim to bridge the gap between neuroscience and artificial intelligence to unlock the full potential of these networks. Our research demonstrates how insight from neurology, biology and physics can innovate and enhance modern DNNs and training methods. Conversely, advancements in AI offer valuable perspectives that deepen our understanding of biological neural processes. We believe that combining ideas from neuroscience and AI is essential to exploring new frontiers in both disciplines.\",\r\n    image: \"/images/critical_artificial_nn.png\"\r\n  },\r\n  {\r\n    id: 5,\r\n    title: \"motus med\",\r\n    shortDescription: \"Transforming the epilepsy diagnostic pathway through accessible & intelligent movement analysis\",\r\n    fullDescription: <div>\r\n    <a href=\"https://motusmed.de\">motus med</a> is a video analysis-based digital health tool intended to assist in the diagnosis and monitoring of persons with abnormal movements, seizures, or epilepsy. Videos of suspected videos are uploaded to our platform, undergo automated analysis to detect movement patterns characteristic of seizures, and can be securely shared with a specialist for additional visual review. Through motus med, we apply several vision based AI models that we have developed in the lab.  Motus med integrates with a variety of smartphones and home cameras in order to provide a device agnostic, flexible, and scalable digital solution. The analysis results are provided to users to assist in decision-making during the diagnostic stage and for ongoing monitoring and management of disease activity in persons with epilepsy.\r\n    {/* <br />\r\n    <a href=\"https://motusmed.de\">Motus med</a> */}\r\n    </div>,\r\n    image: \"/images/motusmed.png\"\r\n  },\r\n  {\r\n    id: 6,\r\n    title: \"ALVEEG\",\r\n    shortDescription: \"Ambulatory long-term video-EEG monitoring\",\r\n    fullDescription: \r\n    <div>\r\n  <a href=\"https://www.alveeg.de\">ALVEEG</a> is a prospective, multicentre, randomized and controlled intervention study. In Germany, people with seizure disorders often have to wait months for a long-term video-EEG which is traditionally only performed in specialized hospitals. This can greatly delay the correct diagnosis and treatment. New sensor technologies and data analysis supported by artificial intelligence are opening up new diagnostic approaches. The aim of the project is to improve the care of people with seizure disorders by providing access to long-term video-EEGs in the home setting.\r\n    </div>,\r\n    image: \"/images/project_alveeg.jpg\"\r\n  },\r\n{\r\n    id: 7,\r\n    title: \"Medical Edge AI\",\r\n    shortDescription: \"M/EDGE\",\r\n    fullDescription: \"With their close integration of programmable microelectronics, sensors and actuators, modern medical devices have opened up fundamentally new diagnostic and therapeutic possibilities. These devices require integration of artificial intelligence and autonomy directly in the medical device, i.e. medical edge computing. Together with partners from academia, med tech and semiconductor industries, the M/EDGE project aims to develop an electronics platform for highly integrated medical edge artificial intelligence.\",\r\n    image: \"/images/medge-logo.png\"\r\n  },\r\n  // {\r\n  //   id: 5,\r\n  //   title: \"UM-EEG\",\r\n  //   shortDescription: \"A low dimensional, universal and highly semantic Map of EEGs using deep learning.\",\r\n  //   fullDescription: \"A prospective multicenter randomised controlled study on the diagnostic yield of ambulant long term video EEG monitoring in patients with suspected epilepsy.\",\r\n  //   image: \"/images/project_video_eeg.webp\"\r\n  // },\r\n  // {\r\n  //   id: 6,\r\n  //   title: \"UM-EEG\",\r\n  //   shortDescription: \"A low dimensional, universal and highly semantic Map of EEGs using deep learning.\",\r\n  //   fullDescription: \"A prospective multicenter randomised controlled study on the diagnostic yield of ambulant long term video EEG monitoring in patients with suspected epilepsy.\",\r\n  //   image: \"/images/project_video_eeg.webp\"\r\n  // },\r\n];\r\n\r\nfunction ProjectCard({ project, isExpanded, onClick }) {\r\n  return (\r\n    <div className={`project-card ${isExpanded ? 'expanded' : ''}`} onClick={onClick}>\r\n      {!isExpanded?<img src={project.image} alt={project.title} />:null}\r\n      <h3>{project.title}</h3>\r\n      <p>{isExpanded ? project.fullDescription : project.shortDescription }</p>\r\n      {!isExpanded?<body className=\"more-text\">More...</body>:null}\r\n    </div>\r\n  );\r\n}\r\n\r\nfunction Projects() {\r\n  const [expandedId, setExpandedId] = useState(null);\r\n\r\n  const handleCardClick = (id) => {\r\n    setExpandedId(expandedId === id ? null : id);\r\n  };\r\n\r\n  return (\r\n    <section id=\"projects\">\r\n      <h2 className=\"section-title\">Projects</h2>\r\n      <div className=\"projects-container\">\r\n        {projectsData.map((project) => (\r\n          <ProjectCard\r\n            key={project.id}\r\n            project={project}\r\n            isExpanded={expandedId === project.id}\r\n            onClick={() => handleCardClick(project.id)}\r\n          />\r\n        ))}\r\n      </div>\r\n    </section>\r\n  );\r\n}\r\n\r\nexport default Projects;\r\n","import React, { useState } from 'react';\r\nimport './Team.css';\r\nconst membersData = [\r\n  { name: 'Christian Meisel', \r\n    role: 'Principal Investigator', \r\n    image: 'images/team/christian.jpg',\r\n    desc: ''\r\n  },\r\n  // { name: 'Agustina Aragon Daud', \r\n  //   role: 'Pre-Doctoral Intern', \r\n  //   image: '/images/team/agustina.jpeg',\r\n  //   desc: \"Agustina is a Pre-Doctoral Research Intern at the Bernstein Center for Computational Neuroscience Berlin. She graduated with honors from Psychology with a focus in Neuroscience from Universidad Favaloro, in Buenos Aires, Argentina. Her current research involves using machine learning for predictive time series analysis in epilepsy, utilizing both iEEG and ECG data.\"\r\n  // },\r\n  { name: 'Alexander Nelde', \r\n    role: 'PhD Student', \r\n    image: '/images/team/alex.jpg',\r\n    desc: \"\"\r\n  },\r\n  { name: 'Amrit Kashyap', \r\n    role: 'Postdoc', \r\n    image: '/images/team/amrit.jpg',\r\n    desc: \"\"\r\n  },\r\n  { name: 'Dominik D. Kranz', \r\n    role: 'PhD Student', \r\n    image: '/images/team/dominik.jpg',\r\n    desc: \"I studied Biophysics and love interdisciplinary research. My interests include pretty much everything that's cool, new and shiny, but my specialty is applying and adapting neural network architectures for biosignal processing, with a focus on ECG and EEG analysis. I especially enjoy bringing these models to the clinic, where they can help improve patient care. \"\r\n  },\r\n  { name: 'Ela Marie Akay', \r\n    role: 'Medical Doctor', \r\n    image: 'images/team/ela_picture.jpg',\r\n    desc: \"As a neurology resident, I am interested in neurovascular medicine and using Artificial Intelligence to improve patient outcomes in neurocritical care and stroke medicine. In my research, I use routinely collected data for neurocritical and stroke unit patients to generate insights into different neurovascular pathologies. I am also fascinated by the broader implications of AI applications in everyday clinical practice and effects on neurological patients and the healthcare system at large.\"\r\n  },\r\n  { name: 'Gadi Miron', \r\n    role: 'Medical Doctor', \r\n    image: '/images/team/gadi.jpg',\r\n    desc: <div>I am a neurologist and researcher with a special interest in epilepsy and digital health. My work focuses on understanding and addressing diagnostic challenges of people with epilepsy through computational analysis of EEG, imaging, and video data. Studies include AI-based video analysis of seizure semiology, retrospective clinical studies, EEG analysis for predicting seizures and long-term cognitive outcomes, and MRI analysis to better understand cognitive dysfunction in epilepsy. I also work to translate our research into clinical practice by developing a digital health tool, <a href=\"https://motusmed.de\">https://motusmed.de</a>, currently being tested at Charité clinics.\r\n\r\n    </div>\r\n    \r\n  },\r\n  { name: 'Jonas Stelzer', \r\n    role: 'Medical Student', \r\n    image: 'images/team/JonasS.jpg',\r\n    desc: \"Currently a medical student at Charité University Hospital with a background in Economics from UCL, I am fascinated by the relationship between physiological cycles, such as heart rate variability, and brain states. By leveraging wearables, I am interested in bridging the gap between costly, hard-to-access brain activity data and consumer-grade health monitoring.\"\r\n  },\r\n  { name: 'Laura Krumm', \r\n    role: 'PhD Student', \r\n    image: 'images/team/LauraK.png',\r\n    desc: \"\"\r\n  },\r\n  { name: 'Lida Antonakopoulou', \r\n    role: 'Medical Doctor', \r\n    image: 'images/team/lidaA.png',\r\n    desc: \"\"\r\n  },\r\n  { name: 'Maximilian Schöls', \r\n    role: 'Medical Doctor', \r\n    image: 'images/team/Maximilian_Schoels.jpg',\r\n    desc: \"\"\r\n  },\r\n  { name: 'Mustafa Halimeh', \r\n    role: 'PhD Student', \r\n    image: '/images/team/Mustafa.jpg',\r\n    desc: \"Mustafa is a computer scientist working on data-driven pipelines to allow better long-term monitoring and treatment of neurological disorders. His current research involves applying state-of-the deep learning models and analytic tools on data recorded from wearables and videos to detect and predict seizures in epilepsy.\"\r\n  },\r\n  { name: 'Paul Müller', \r\n    role: 'Postdoc', \r\n    image: '/images/team/paul.jpg',\r\n    desc: \"I am interested in cortical dynamics and their relation to cognitive function, especially in the context of epilepsy. Beyond my goal to improve our general understanding of cortical dynamics I aim to identify meaningful biomarkers for epilepsy management. My methods include neuronal, statistical and machine learning models, non-linear time series analysis within the framework of brain criticality, and the evaluation of behavioural testing.\"\r\n  },\r\n  { name: 'Robert Terziev', \r\n    role: 'Medical Doctor', \r\n    image: '/images/team/robert.jpg',\r\n    desc: \"\"\r\n  },\r\n  { name: 'Simon Vock', \r\n    role: 'PhD Student', \r\n    image: 'images/team/SimonV.jpg',\r\n    desc: \"I am fascinated by the parallels between artificial neural networks and biological brains. My research focuses on critical phase transitions in machine learning, exploring how networks of simple units can give rise to complex, intelligent behavior. By applying insights from deep learning and physics, I study neural systems with the aim of advancing our understanding of both artificial and biological intelligence. Through this work, I hope to contribute to the development of more efficient AI systems and innovative treatments for neurological disorders.\"\r\n  },\r\n  { name: 'Tim Wiegand', \r\n    role: 'Medical Doctor', \r\n    image: 'images/team/tim.png',\r\n    desc: \"I am a neurology resident at Charité and a postdoctoral researcher in the computational neurology group. My doctoral thesis focused on advanced neuroimaging techniques in neurotrauma and neurodegenerative disease. Currently, my research centers on predictive modeling in neurology. More specifically, I am working on forecasting increases in intracranial pressure based on time-series data from the ICU. I am co-author of “Künstliche Intelligenz in der Medizin”, a textbook on AI in medicine.\"\r\n  },\r\n  { name: 'Claudia Gorski', \r\n    role: 'Administration', \r\n    image: 'images/team/claudia.jpg',\r\n    desc: \"\"\r\n  },\r\n\r\n\r\n  // Add other team members\r\n];\r\n\r\nfunction TeamCard({ member, isExpanded, onClick }) {\r\n  return (\r\n    <div className={`team-card ${isExpanded ? 'expanded' : ''}`} onClick={onClick}>\r\n      <img src={member.image} alt={member.name} />\r\n      <h3>{member.name}</h3>\r\n      <p>{member.role}</p>\r\n      <p>{isExpanded ? member.desc : (member.desc === '' ? null : <body className={'more-text'}>More...</body>)}</p>\r\n    \r\n    </div>\r\n  );\r\n}\r\n\r\nfunction Team() {\r\n  const [expandedId, setExpandedId] = useState(null);\r\n\r\n  const handleCardClick = (id) => {\r\n    setExpandedId(expandedId === id ? null : id);\r\n  };\r\n\r\n  return (\r\n    <div className=\"team-section-container\">\r\n    <section id=\"team\">\r\n      <div className=\"team-container-container\">\r\n      <h2 className=\"section-title team-title\">Team</h2>\r\n        <div className=\"team-container\">\r\n        {membersData.map((member) => (\r\n          <TeamCard\r\n            key={member.name}\r\n            member={member}\r\n            isExpanded={expandedId === member.name}\r\n            onClick={() => handleCardClick(member.name)}\r\n          />\r\n        ))}\r\n      </div>\r\n      </div>\r\n    </section>\r\n    </div>\r\n  );\r\n}\r\n\r\n// function Team() {\r\n//   const [teamMembers, setTeamMembers] = useState([]);\r\n\r\n//   useEffect(() => {\r\n//     // In a real app, you'd fetch this data from an API\r\n//     const fetchTeamMembers = async () => {\r\n//       // Simulating API call\r\n//       const members = [\r\n//         { name: 'Prof Christian Meisel', \r\n//           role: 'Principal Investigator', \r\n//           image: 'images/logo_group.webp',\r\n//           desc: ''\r\n//         },\r\n//         // { name: 'Agustina Aragon Daud', \r\n//         //   role: 'Pre-Doctoral Intern', \r\n//         //   image: '/images/team/agustina.jpeg',\r\n//         //   desc: \"Agustina is a Pre-Doctoral Research Intern at the Bernstein Center for Computational Neuroscience Berlin. She graduated with honors from Psychology with a focus in Neuroscience from Universidad Favaloro, in Buenos Aires, Argentina. Her current research involves using machine learning for predictive time series analysis in epilepsy, utilizing both iEEG and ECG data.\"\r\n//         // },\r\n//         { name: 'Alexander Nelde', \r\n//           role: 'PhD Student', \r\n//           image: '/images/team/alex.jpg',\r\n//           desc: \"\"\r\n//         },\r\n//         { name: 'Amrit Kashyap', \r\n//           role: 'Postdoc', \r\n//           image: '/images/team/amrit.jpg',\r\n//           desc: \"\"\r\n//         },\r\n//         { name: 'Dominik D. Kranz', \r\n//           role: 'PhD Student', \r\n//           image: '/images/team/dominik.jpg',\r\n//           desc: \"I studied Biophysics at Humboldt-Universität zu Berlin, and love interdisciplinary research. My interests include pretty much everything that's cool, new and shiny, but my specialty is applying and adapting Neural Network architectures for biosignal processing, with a focus on ECG and EEG analysis. I especially enjoy bringing these models to the clinic, where they can help to improve patient care. \"\r\n//         },\r\n//         { name: 'Ela Marie Akay', \r\n//           role: 'Medical Doctor', \r\n//           image: 'images/logo_group.webp',\r\n//           desc: \"\"\r\n//         },\r\n//         { name: 'Gadi Miron', \r\n//           role: 'Medical Doctor', \r\n//           image: '/images/team/gadi.jpg',\r\n//           desc: <div>I am a Neurologist and researcher with a special interest in epilepsy and digital health. My work focuses on understanding and addressing diagnostic challenges of people with epilepsy through computational analysis of EEG, imaging, and video data. Studies include AI-based video analysis of seizure semiology, retrospective clinical studies, EEG analysis for predicting seizures and long-term cognitive outcomes, and MRI analysis to better understand cognitive dysfunction in epilepsy. I also work to translate our research into clinical practice by developing a digital health tool, <a href=\"https://motusmed.de\">https://motusmed.de</a>, currently being tested at Charité clinics.\r\n \r\n//           </div>\r\n          \r\n//         },\r\n//         { name: 'Jonas Stelzer', \r\n//           role: 'Medical Student', \r\n//           image: 'images/team/JonasS.jpg',\r\n//           desc: \"Currently a medical student at Charité University Hospital with a background in Economics from UCL, I am fascinated by the relationship between physiological cycles, such as heart rate variability, and brain states. By leveraging wearables, I am interested in bridging the gap between costly, hard-to-access brain activity data and consumer-grade health monitoring.\"\r\n//         },\r\n//         { name: 'Laura Krumm', \r\n//           role: 'PhD Student', \r\n//           image: 'images/team/LauraK.png',\r\n//           desc: \"\"\r\n//         },\r\n//         { name: 'Lida Antonakopoulou', \r\n//           role: 'Medical Doctor', \r\n//           image: 'images/team/LidaA.jpg',\r\n//           desc: \"\"\r\n//         },\r\n//         // { name: 'Lily Strittmatter', \r\n//         //   role: 'Bachelor Student', \r\n//         //   image: 'https://via.placeholder.com/150',\r\n//         //   desc: \"\"\r\n//         // },\r\n//         { name: 'Maximilian Schöls', \r\n//           role: 'Medical Doctor', \r\n//           image: 'images/logo_group.webp',\r\n//           desc: \"\"\r\n//         },\r\n//         { name: 'Mustafa Halimeh', \r\n//           role: 'PhD Student', \r\n//           image: '/images/team/Mustafa.jpg',\r\n//           desc: \"Mustafa is a computer scientist working on data-driven pipelines to allow better long-term monitoring and treatment of neurological disorders. His current research involves applying state-of-the deep learning models and analytic tools on data recorded from wearables and videos to detect and predict seizures in epilepsy.\"\r\n//         },\r\n//         { name: 'Paul Müller', \r\n//           role: 'PhD Student', \r\n//           image: '/images/team/paul.jpg',\r\n//           desc: \"I am interested in cortical dynamics and their relation to cognitive function, especially in the context of epilepsy. Beyond my goal to improve our general understanding of cortical dynamics I aim to identify meaningful biomarkers for epilepsy management. My methods include neuronal, statistical and machine learning models, non-linear time series analysis within the framework of brain criticality, and the evaluation of behavioural testing.\"\r\n//         },\r\n//         { name: 'Robert Terziev', \r\n//           role: 'Medical Doctor', \r\n//           image: '/images/team/robert.jpg',\r\n//           desc: \"\"\r\n//         },\r\n//         { name: 'Simon Vock', \r\n//           role: 'PhD Student', \r\n//           image: 'images/team/SimonV.jpg',\r\n//           desc: \"I am fascinated by the parallels between artificial neural networks and biological brains. My research focuses on critical phase transitions in machine learning, exploring how networks of simple units can give rise to complex, intelligent behavior. By applying insights from deep learning and physics, I study neural systems with the aim of advancing our understanding of both artificial and biological intelligence. Through this work, I hope to contribute to the development of more efficient AI systems and innovative treatments for neurological disorders.\"\r\n//         },\r\n\r\n\r\n//         // Add other team members\r\n//       ];\r\n//       setTeamMembers(members);\r\n//     };\r\n\r\n//     fetchTeamMembers();\r\n//   }, []);\r\n\r\n//   return (\r\n//     // <div className=\"team-section-container\">\r\n//     <section id=\"team\">\r\n//       <div className=\"team-container-container\">\r\n//       <h2 className=\"section-title team-title\">Team</h2>\r\n//         <div className=\"team-container\">\r\n//           {teamMembers.map((member, index) => (\r\n//             <div key={index} className=\"team-card\">\r\n//               <img src={member.image} alt={member.name} />\r\n//               <h3>{member.name}</h3>\r\n//               <p>{member.role}</p>\r\n//               <p>{member.desc}</p>\r\n//             </div>\r\n//           ))}\r\n//       </div>\r\n//       </div>\r\n//     </section>\r\n//       // </div>\r\n//   );\r\n// }\r\n\r\nexport default Team;\r\n","import React from \"react\";\r\nimport \"./Alumni.css\";\r\n\r\nconst alumniNames = [\r\n  \"Amrit Kashyap\",\r\n  \"Jonas Stelzer\",\r\n  \"Paul Müller\",\r\n  \"Gadi Miron\",\r\n  \"Lida Antonakopoulou\",\r\n  \"Agustina Aragon Daud\",\r\n  \"Lily Strittmatter\",\r\n  \"Mario Andina\",\r\n  \"Georg von Arnim\",\r\n];\r\n\r\nexport default function Alumni() {\r\n  return (\r\n    <section id=\"alumni\">\r\n      <h2 className=\"section-title\">Alumni</h2>\r\n\r\n      <div className=\"alumni-card\">\r\n        <img\r\n          src=\"/images/logo_group.webp\"\r\n          alt=\"Lab logo\"\r\n          className=\"alumni-logo\"\r\n        />\r\n\r\n        <ul className=\"alumni-list\">\r\n          {alumniNames.map((n) => (\r\n            <li key={n}>{n}</li>\r\n          ))}\r\n        </ul>\r\n\r\n        {/* If you want roles/years later, add a small muted line here */}\r\n        {/* <p className=\"alumni-note\">2019–2024 cohorts</p> */}\r\n      </div>\r\n    </section>\r\n  );\r\n}\r\n","// src/utils/sanitizeLatex.js\r\n\r\nexport function sanitizeLatex(text) {\r\n    if (!text) return '';\r\n  \r\n    let sanitized = text;\r\n  \r\n    // Replace escaped characters\r\n    const replacements = {\r\n      '\\&': '&',\r\n      '\\\\%': '%',\r\n      '\\\\#': '#',\r\n      '\\\\$': '$',\r\n      '\\\\_': '_',\r\n      '\\\\{': '{',\r\n      '\\\\}': '}',\r\n      '\\\\~{}': ' ',\r\n      '\\\\^{}': '^',\r\n      '\\\\textbf{': '',\r\n      '\\\\textit{': '',\r\n      '\\\\texttt{': '',\r\n      '}': '',\r\n      '{': '',\r\n      '\\\\ ': ' ', // Handles escaped spaces\r\n    };\r\n  \r\n    Object.keys(replacements).forEach((key) => {\r\n      const regex = new RegExp(key, 'g');\r\n      sanitized = sanitized.replace(regex, replacements[key]);\r\n    });\r\n  \r\n    // Handle accented characters (basic implementation)\r\n    const accentedReplacements = {\r\n      \"\\\\'{a}\": 'á',\r\n      \"\\\\`{a}\": 'à',\r\n      \"\\\\~{a}\": 'ã',\r\n      \"\\\\^{a}\": 'â',\r\n      '\\\\.{a}': 'a',\r\n      \"\\\\'e\": 'é',\r\n      \"\\\\`e\": 'è',\r\n      \"\\\\~e\": 'ẽ',\r\n      \"\\\\^e\": 'ê',\r\n      '\\\\.e': 'e',\r\n      // Add more as needed\r\n    };\r\n  \r\n    Object.keys(accentedReplacements).forEach((key) => {\r\n      const regex = new RegExp(key, 'g');\r\n      sanitized = sanitized.replace(regex, accentedReplacements[key]);\r\n    });\r\n  \r\n    // Remove remaining LaTeX commands\r\n    sanitized = sanitized.replace(/\\\\[a-zA-Z]+\\{([^}]+)\\}/g, '$1'); // e.g., \\emph{word} -> word\r\n  \r\n    return sanitized;\r\n  }\r\n  ","import React, { useState, useEffect } from 'react';\r\nimport bibtexParse from 'bibtex-parse-js';\r\nimport './Publications.css';\r\nimport { sanitizeLatex } from '../utils/sanitizeLatex';\r\n\r\nfunction Publications() {\r\n  const [publications, setPublications] = useState([]);\r\n  const [expandedPub, setExpandedPub] = useState(null);\r\n  const [searchTerm, setSearchTerm] = useState('');\r\n\r\n  useEffect(() => {\r\n    const fetchAndParseBibTeX = async () => {\r\n      try {\r\n        const response = await fetch(`/publications.bib?ts=${Date.now()}`);\r\n        const bibtexText = await response.text();\r\n        const parsed = bibtexParse.toJSON(bibtexText);\r\n        const formatted = parsed.map(entry => ({\r\n          id: entry.citationKey,\r\n          title: sanitizeLatex(entry.entryTags.title),\r\n          authors: entry.entryTags.author,\r\n          journal: sanitizeLatex(entry.entryTags.journal),\r\n\t\tbook: sanitizeLatex(entry.entryTags.booktitle),\r\n          year: entry.entryTags.year,\r\n          doi: entry.entryTags.doi,\r\n          url: entry.entryTags.url,\r\n          abstract: sanitizeLatex(entry.entryTags.abstract),\r\n          entryType: entry.entryType,\r\n\t\t  publisher: entry.entryTags.publisher,\r\n\t\t  volume: entry.entryTags.volume,\r\n\t\t  pages: entry.entryTags.pages,\r\n \r\n          // Add more fields as needed\r\n        }));\r\n        \r\n        setPublications(formatted);\r\n      } catch (error) {\r\n        console.error('Error fetching or parsing BibTeX file:', error);\r\n      }\r\n    };\r\n\r\n    fetchAndParseBibTeX();\r\n  }, []);\r\n\r\n\r\n  // Group filtered publications by year\r\n  const publicationsByYear = publications.reduce((acc, pub) => {\r\n    const year = pub.year || 'Unknown Year';\r\n    if (!acc[year]) {\r\n      acc[year] = [];\r\n    }\r\n    acc[year].push(pub);\r\n    return acc;\r\n  }, {});\r\n\r\n  // Sort years in descending order\r\n  const sortedYears = Object.keys(publicationsByYear).sort((a, b) => b - a);\r\n\r\n  const handleExpand = (id) => {\r\n    setExpandedPub(prev => (prev === id ? null : id));\r\n  };\r\n\r\n  return (\r\n    <section id=\"publications\">\r\n      <h2 className=\"section-title\">Publications</h2>    \r\n      {sortedYears.map(year => (\r\n        <div key={year} className=\"year-section\">\r\n          <h3>{year}</h3>\r\n          <div className=\"year-container\">\r\n            {publicationsByYear[year].map(pub => (\r\n              <div\r\n                key={pub.id}\r\n                className={`publication-card ${expandedPub === pub.id ? 'expanded' : ''}`}\r\n                onClick={() => handleExpand(pub.id)}\r\n              >\r\n                <h4>{pub.title}</h4>\r\n                <p style={{color:\"grey\", marginBottom:\"20px\", marginTop:\"20px\"}}>{pub.authors}</p>\r\n                <p><i>{pub.journal || 'Preprint'}</i></p>\r\n                <body className='more-text'>{expandedPub === pub.id ? '' : 'More...'}</body>\r\n                {expandedPub === pub.id && (\r\n                  <>\r\n                    {pub.abstract && (\r\n                      <p><strong>Abstract:</strong> {pub.abstract}</p>\r\n                    )}\r\n                    {pub.doi && (\r\n                      <p>\r\n                        <strong>DOI:</strong> <a href={`https://doi.org/${pub.doi}`} target=\"_blank\" rel=\"noopener noreferrer\">{pub.doi}</a>\r\n                      </p>\r\n                    )}\r\n                    {pub.url && (\r\n                      <p>\r\n                        <strong>URL:</strong> <a href={pub.url} target=\"_blank\" rel=\"noopener noreferrer\">View Publication</a>\r\n                      </p>\r\n                    )}\r\n                  </>\r\n                )}\r\n              </div>\r\n            ))}\r\n          </div>\r\n        </div>\r\n      ))}\r\n    </section>\r\n  );\r\n}\r\n\r\nexport default Publications;\r\n","import React from 'react';\r\n\r\nfunction Footer() {\r\n  return (\r\n    <div id=\"footer\">\r\n    <footer>\r\n      <p>\r\n        Contact:{\" \"}\r\n        <a href=\"mailto:computational-neurology@charite.de\">\r\n        computational-neurology at charite.de\r\n        </a>\r\n      </p>\r\n      <p>&copy; {new Date().getFullYear()} Computational Neurology Research Group</p>\r\n    </footer>\r\n    </div>\r\n  );\r\n\r\n}\r\n\r\nexport default Footer;","import React from \"react\";\r\nimport { Link } from \"react-router-dom\";\r\nimport \"./CompetitionAnouncement.css\";\r\n\r\nexport default function CompetitionAnouncement() {\r\n  return (\r\n    <section id=\"competition-announcement\">\r\n      <h2 className=\"section-title\">Video-Seizure Competition 2026</h2>\r\n\r\n      <div className=\"competition-content\">\r\n        <p>\r\n          In partnership with The International Conference on Artificial Intelligence in Epilepsy and Other Neurological Disorders (2026), \r\n          the Section on Computational Neurology at Charité - Universitätsmedizin Berlin in Germany and partners are organizing a video-based seizure detection challenge. \r\n        </p>\r\n\r\n    <Link to=\"/video_challenge\" className=\"competition-button\">\r\n      Details\r\n    </Link>\r\n      </div>\r\n    </section>\r\n  );\r\n}\r\n","import React from \"react\";\r\nimport \"./Competition.css\";\r\n\r\nexport default function Competition() {\r\n  return (\r\n    <section id=\"competition\">\r\n      <h2 className=\"section-title\">Video-based Seizure Detection Challenge (2026)</h2>\r\n\r\n      <div className=\"competition-intro\">\r\n        <p>\r\n          In partnership with <strong><a href= \"https://www.aiepilepsy-neuro.com/\" >The International Conference on Artificial Intelligence in Epilepsy and Other Neurological Disorders (2026)</a></strong>, the Section on Computational Neurology at Charité – Universitätsmedizin Berlin and partners are organizing a video-based seizure detection challenge.\r\n        </p>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Key dates</h3>\r\n        <div className=\"keydates\">\r\n          <div className=\"k\">Mid November 2025</div><div className=\"v\">Challenge begins.</div>\r\n          <div className=\"k\">February 23, 2025</div><div className=\"v\">Submission closes — submit early.</div>\r\n          <div className=\"k\">March 16–19, 2025</div><div className=\"v\">Winners announced during the AI in Epilepsy 2026 conference.</div>\r\n        </div>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Background</h3>\r\n        <p>\r\n         Epilepsy is a common neurological disorder affecting around 50 million people worldwide. Infantile epileptic spasm syndrome (IESS) is an early developmental and epileptic encephalopathy condition affecting approximately 1 in 2000-2500 infants in their first year of life. IESS is characterized by epileptic spasms which are sudden motor movements involving the head, arms, and legs. Despite the stereotypical nature of epileptic spasms, diagnosis is frequently delayed by weeks to months due to misidentification of symptoms as benign physiological occurrences or failure to recognize any abnormality by physicians or parents. These delays are associated with long-term poor cognitive outcomes, inadequate seizure control, increased disability, and higher healthcare costs. The widespread availability of smartphones and advancements in artificial intelligence (AI) may open new avenues for decision support in diagnosing these seizures [1].\r\n        </p>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Objective</h3>\r\n        <p>\r\n          This challenge aims to build a video-based seizure detection model that detects if a <strong>5-second video segment</strong> contains an epileptic spasm or not. Video content is anonymized using a pose estimation algorithm. The pose estimation data includes a number of landmarks that represent key points on the skeleton of the child's body (further details below). Every 5-second segment contains 150 frames (fps=30), and pose estimation is performed on each frame. In this challenge, we are providing a training dataset to build the seizure detection models as a binary classification tast (video segment contains a seizure yes/no). The models will then be evaluated on large out-of-sample dataset.\r\n        </p>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Data description</h3>\r\n        <p>\r\n          The data includes 5-second video segments recorded from smartphones or other cameras from different children. Some of the children were diagnosed with infantile spasms. Each 5-second video segment may contain a seizure (at any time point) or could be normal, i.e., seizure-free. Across the training dataset, the same child may contribute multiple video segment from both classes or only from one class. To extract relevant movement while also preserving data privacy, we used the mediapipe library [2] to extract the pose landmarks from the children’s video segments. The total number of landmarks is 33, and each landmark has 3 coordinates reflecting the position on the x, y, z axes, and two values (visibility and presence) referring to the degree of the presence of the landmark inside the frame scene. Note, that mediapipe may sometimes not extract the landmarks for some frames due to video quality issues. We used mediapipe version 0.10.21 with the model pose_landmarker_heavy.task.\r\n        </p>\r\n      </div>\r\n\r\n           <div className=\"competition-card\">\r\n  <h3>Training data</h3>\r\n  <p>\r\n    The shared training data is a set of .npy files containing the landmarks from each frame of the respective 5-second segments (in total 150 frames corresponding to 30 frames per second (fps)). Missed frames have ‘nan’ landmarks. Besides the .npy files, there is a .csv file (comma ‘,’ separated) containing the true labels of those video segments along with their names (two columns; first column: segment_name (string), second column: label (int 0 or 1; 1 for seizure, 0 no seizure).\r\n  </p>\r\n  <p>The .npy files have the following naming convention:</p>\r\n    <code>child_{'{'}id{'}'}_{'{'}segment{'}'}</code>\r\n    <p>where <code>id</code> and <code>segment</code> are both integers. Segments belonging to the same child have the same <code>id</code>. Here is an example of code to read the landmarks .npy file:</p>\r\n\r\n\r\n  <div className=\"codeblock\">\r\n          <pre><code>{`import numpy as np\r\n\r\n# Read a .npy file containing video 5-second segments landmarks\r\nlmk_arr = np.load('child_1_1.npy')\r\n# lmk_arr.shape -> (150, 33, 5) -> (n_frames, n_landmarks, [x, y, z, visibility, presence])\r\n# lmk_arr.dtype -> float64\r\n\r\n# Get frames with nan landmarks\r\nis_nan = np.isnan(lmk_arr)\r\nnan_inx = np.any(is_nan, axis=(1, 2))\r\n`}\r\n  </code>\r\n</pre>\r\n</div>\r\n<p>Here is an example of code to read the .csv file:</p>\r\n        <div className=\"codeblock\">\r\n          <pre><code>{`import pandas as pd\r\n\r\ntrain_df = pd.read_csv('train_data.csv', sep=',')\r\n\r\n# Example:\r\n# segment_name,label\r\n# child_1_1.npy,1\r\n# child_1_2.npy,0`}</code></pre>\r\n        </div>\r\n\r\n      </div>\r\n\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Output data</h3>\r\n        <p>\r\n         The prediction from each submitted model must be summarized in one single .csv file containing the predicted labels as 1 for seizure and 0 for non-seizure for each 5-second video segment (.npy file) along with the file name. Thus, the output .csv file must have only two columns (first column: file name, second column: label). Please note that the predicted labels are required per each 5-second video segment and not per each child, so participants must not predict if a child has infantile spasms or not.\r\n        </p>\r\n      </div>\r\n\r\n\r\n    <div className=\"competition-card\">\r\n      <h3>Performance metrics</h3>\r\n      <p>Based on the predicted labels from each participant’s model, we will compute the performance metrics of sensitivity, specificity, accuracy, and F1-score using an out-of-sample test dataset. These metrics will be computed as sample-based, i.e., each 5-second video segment will have a single prediction value of either 1 or 0. We will report the metrics as follows:\r\n        </p>\r\n      <ul>\r\n        <li><strong>Sensitivity</strong>: TP / (TP + FN)</li>\r\n        <li><strong>Specificity</strong>: TN / (TN + FP)</li>\r\n        <li><strong>Precision</strong>: TP / (TP + FP)</li>\r\n        <li><strong>F1-score</strong>: 2 × (Precision × Sensitivity) / (Precision + Sensitivity)</li>\r\n      </ul>\r\n\r\n    </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Evaluation</h3>\r\n        <p>\r\n          Submissions will be evaluated on an out-of-sample dataset using the above defined performance metrics. The F1 score will be used as a main metric to rank the performances and, in case of tie of F1 score values, sensitivity will be considered as a secondary ranking metric.\r\n        </p>\r\n      </div>\r\n\r\n\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Awards</h3>\r\n        <p>Our sponsors are generously offering $10,000 prizes for the winning participants. This prize money will be split among only the best two algorithms as follows:</p>\r\n        <ul className=\"awards\">\r\n          <li><strong>#1:</strong> $7,000</li>\r\n          <li><strong>#2:</strong> $3,000</li>\r\n        </ul>\r\n        <p>\r\n          Both winning participant teams (first/second place) are required to send their detailed solutions with the source code for final verification. This will demand them to agree on sharing their code under a CC-BY- SA 4.0 license to receive the full awarded prize money.\r\n</p>\r\n        <p>\r\n          The challenge organizers will write a summary of the outcome of the challenge in a leading journal in our field. The top challenge contributors will be invited to contribute to this paper to describe their methodology.\r\n    </p>\r\n\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Organizers</h3>\r\n        <p>\r\n         The challenge is organized by the Section on Computational Neurology at Charité - Universitätsmedizin Berlin in Germany, in collaboration with sponsor1, sponsor2 and sponsor3. \r\n\r\n        For questions to the organizers, you can contact Christian Meisel or Mustafa Halimeh: <a href=\"mailto:computational-neurology@charite.de\">computational-neurology@charite.de</a>\r\n\r\n        </p>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Legal statement</h3>\r\n        <p>Participants must acknowledge that the shared data must only be used for this competition.</p>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Submission guidelines</h3>\r\n        Participants should provide a pre-trained model packaged as a Docker image. The Docker image should be downloadable from an image registry. Participants can have a maximum of three different submissions. An abstract describing the methodology and performance of the training data is optional. Participants are invited to submit a poster in addition to the challenge submission, more details on poster submission are available on the <a href=\"https://www.aiepilepsy-neuro.com/\"> AI in epilepsy conference website</a>. \r\n        <p><strong>Docker requirements:</strong></p>\r\n        <p>The docker image must contain two volumes, and define two environment variables:</p>\r\n        <div className=\"codeblock\">\r\n          <pre><code>{`VOLUME [\"/data\"]\r\nVOLUME [\"/output\"]\r\nENV INPUT=\"\"\r\nENV OUTPUT=\"\"`}</code></pre>\r\n        </div>\r\n        <p>\r\n          Where <code>INPUT</code> and <code>OUTPUT</code> variables contain the path to test-out dataset and .csv file relative to /data and /output.\r\n        </p>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Computing platform</h3>\r\n        <p>\r\n          We will run all submitted models and algorithms on our HPC on premises. The device will have no internet access during the evaluation of the submissions. The computer is a DELL workstation with 2 Nvidia RTX 6000 GPUs, 32 CPU cores, and 48 GB RAM memory in each GPU. Windows 11 is the main OS but also Linux Subsystem is included (WSL ubuntu).\r\n        </p>\r\n      </div>\r\n\r\n      <div className=\"competition-card\">\r\n        <h3>Submission form</h3>\r\n        {/* <div className=\"keydates\">\r\n          <div className=\"k\">Title</div><div className=\"v\">Name of the model</div>\r\n          <div className=\"k\">Docker image</div><div className=\"v\">Registry path to pull</div>\r\n          <div className=\"k\">Authors</div><div className=\"v\">Comma-separated list</div>\r\n          <div className=\"k\">Abstract</div><div className=\"v\">Brief method description</div>\r\n        </div> */}\r\n        <p className=\"smallprint\">\r\n          Please submit your algorithms via submission form (link below).\r\n          The algorithms submitted here remain the strict property of the inventor. Neither the conference organizers nor the challenge sponsors have any intellectual property claims on the algorithms. The conference organizers will not share or disseminate them after the evaluation of the model. They will use the algorithms during the challenge to evaluate performance on a holdout dataset.\r\n\r\nTo be eligible to receive the prize money, at least one co-author of the submitted model must be registered (in person or virtual) for the conference. Teams that are not registered can participate, but they will not be eligible to win.\r\n\r\n        </p>\r\n\r\n      </div>\r\n\r\n      <a\r\n        href=\"https://forms.office.com/Pages/ResponsePage.aspx?id=ORnprz6SLEO8ZsvD7BjQLE1mFpKUXcBDnOuOUqQLSWVUREQ5WEJLVUdFQkE5VTVENVhCUjNJQ0NITCQlQCN0PWcu\"\r\n        target=\"_blank\"\r\n        rel=\"noopener noreferrer\"\r\n        className=\"competition-button\"\r\n      >\r\n        Submit your entry\r\n      </a>\r\n\r\n      <div className=\"refs\">\r\n        <h4>References</h4>\r\n        <ol>\r\n          <li>Miron, G., Halimeh, M., Tietze, S. et al. Detection of epileptic spasms using foundational AI and smartphone videos. npj Digit. Med. 8, 370 (2025). https://doi.org/10.1038/s41746-025-01773-1\r\n          </li>\r\n          \r\n          <li>Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., Zhang, F., Chang, C., Yong, M.G., Lee, J., Chang, W., Hua, W., Georg, M., & Grundmann, M. (2019). MediaPipe: A Framework for Building Perception Pipelines. https://doi.org/10.48550/arXiv.1906.08172</li>\r\n        </ol>\r\n      </div>\r\n    </section>\r\n  );\r\n}","import React from 'react';\r\nimport { BrowserRouter as Router, Routes, Route } from 'react-router-dom';\r\nimport Header from './components/Header';\r\n\r\nimport Projects from './components/Projects';\r\nimport Team from './components/Team';\r\nimport Alumni from './components/Alumni';\r\nimport Publications from './components/Publications';\r\nimport Footer from './components/Footer';\r\nimport Home from './components/Home';\r\nimport CompetitionAnouncement from './components/CompetitionAnouncement';\r\nimport Competition from './components/Competition';\r\n\r\n\r\nfunction App() {\r\n  return (\r\n    <Router>\r\n      <div className=\"App\">\r\n        <Header />\r\n        {/* <Navigation /> */}\r\n        {/* <main>\r\n          {/* <Home /> */}\r\n          {/* <CompetitionAnouncement /> */}\r\n          {/* <Projects /> */}\r\n          {/* <Team /> */}\r\n          {/* <Alumni /> */}\r\n          {/* <Publications /> */}\r\n        {/* </main>  */}\r\n<Routes>         \r\n  <Route\r\n    path=\"/\"\r\n    element={\r\n      <main>\r\n        {/* <Home /> */}\r\n        <CompetitionAnouncement />\r\n        <Projects />\r\n        <Team />\r\n        <Alumni />\r\n        <Publications />\r\n      </main>\r\n    }\r\n  />\r\n    <Route path=\"/video_challenge\" element={<Competition />} />\r\n       </Routes>\r\n\r\n        <Footer />\r\n      </div>\r\n    </Router>\r\n  );\r\n}\r\n\r\nexport default App;","const reportWebVitals = onPerfEntry => {\r\n  if (onPerfEntry && onPerfEntry instanceof Function) {\r\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\r\n      getCLS(onPerfEntry);\r\n      getFID(onPerfEntry);\r\n      getFCP(onPerfEntry);\r\n      getLCP(onPerfEntry);\r\n      getTTFB(onPerfEntry);\r\n    });\r\n  }\r\n};\r\n\r\nexport default reportWebVitals;\r\n","import React from 'react';\r\nimport ReactDOM from 'react-dom/client';\r\nimport './index.css';\r\nimport App from './App';\r\nimport reportWebVitals from './reportWebVitals';\r\nimport './styles/style.css'\r\n\r\nconst root = ReactDOM.createRoot(document.getElementById('root'));\r\nroot.render(\r\n  <React.StrictMode>\r\n    <App />\r\n  </React.StrictMode>\r\n);\r\n\r\n// If you want to start measuring performance in your app, pass a function\r\n// to log results (for example: reportWebVitals(console.log))\r\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\r\nreportWebVitals();\r\n"],"sourceRoot":""}