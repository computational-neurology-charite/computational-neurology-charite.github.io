(this["webpackJsonpcomputational-neurology-charite.github.io"]=this["webpackJsonpcomputational-neurology-charite.github.io"]||[]).push([[0],{25:function(e,a,t){e.exports=t(67)},33:function(e,a,t){},43:function(e,a,t){},44:function(e,a,t){},45:function(e,a,t){},46:function(e,a,t){},63:function(e,a,t){},64:function(e,a,t){},65:function(e,a,t){},66:function(e,a,t){},67:function(e,a,t){"use strict";t.r(a);var n=t(0),i=t.n(n),o=t(22),r=t.n(o),l=(t(33),t(3)),s=t(2),c=t(4);var m=function(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("header",null,i.a.createElement("div",{className:"header-content"},i.a.createElement(l.b,{to:"/",style:{textDecoration:"none",color:"inherit"}},i.a.createElement("h1",{align:"center"},"Computational Neurology")))),i.a.createElement("nav",null,i.a.createElement(c.Link,{to:"home",smooth:!0,duration:500},"News"),i.a.createElement(c.Link,{to:"projects",smooth:!0,duration:500},"Projects"),i.a.createElement(c.Link,{to:"team",smooth:!0,duration:500},"Team"),i.a.createElement(c.Link,{to:"publications",smooth:!0,duration:500},"Publications"),i.a.createElement(c.Link,{to:"footer",smooth:!0,duration:500},"Contact"),i.a.createElement(l.b,{to:"/video_challenge"},"Video Challenge")))};t(43);const d=[{id:1,title:"Computational Inpatient Monitoring",shortDescription:"Predicting patient outcomes using routinely collected data",fullDescription:"The increasing availability of multimodal and continuous 'physiomes' of neurological patients through digital neuromonitoring, new sensor and wearable technologies paired with advanced data analytics offer opportunities for a fundamental transformation in neurology. For inpatient monitoring in intensive care, stroke medicine and epilepsy computational neurology provides vast opportunities for the development of predictive diagnostic methods for specific and time-critical therapies. By leveraging cutting-edge machine learning techniques, our team aims to transform the raw datasets into actionable intelligence, improving the accuracy, efficiency, and scalability of diagnostic processes. Our work focuses on automating the analysis of biosignals and other clinical data to enhance real-time decision-making, reduce the burden on healthcare professionals, and streamline hospital workflows. By seamlessly integrating AI models into clinical environments, we seek to drive innovation in patient care, ultimately improving outcomes and paving the way for a more data-driven healthcare future.",image:"/images/project_dwc.png"},{id:2,title:"Computational Ambulatory Monitoring",shortDescription:"Predicting patient outcomes using routinely collected data",fullDescription:"Enabled by new, wearable sensors and computational analysis, objective methods for continuous, longitudinal monitoring and risk assessments provide opportunities for a fundamental medical transformation towards personalized, proactive and time-critical therapies in the outpatient setting.",image:"/images/Fig_Wearable_DL.jpg"},{id:3,title:"Critical Dynamics in Brain Networks",shortDescription:"Criticality as the optimal set-point of network dynamics",fullDescription:"The brain's ability to process and integrate information across spatial and temporal domains is central to intact cognitive function. Physics and information theory have provided a framework describing an optimal state of information processing. This critical state, poised at the phase transition between chaotic and ceasing neuronal activity, is characterized by an equilibrium between excitation and inhibition in the neuronal network. When a network of neurons operates near a critical phase transition point, a range of information processing functions, including information transmission, integration, storage, dynamic range, and sensitivity to inputs, are optimized simultaneously. While criticality provides a precise framework linking network structure to dynamics, its central claim, that critical dynamics predicts optimal network and thus cognitive function in humans, has not been proven yet. To try to fill this gap by investigating multi-model cortical measurements, e.g., MRI and iEEG, together with cognitive performance evaluation.",image:"/images/criticality.jpg"},{id:4,title:"Neuro-AI",shortDescription:"Critical dynamics in artificial intelligence networks",fullDescription:"Deep Neural Networks (DNNs) have revolutionized numerous fields, yet their training and design remain challenging due to vast parameter spaces and limited theoretical understanding. We here aim to bridge the gap between neuroscience and artificial intelligence to unlock the full potential of these networks. Our research demonstrates how insight from neurology, biology and physics can innovate and enhance modern DNNs and training methods. Conversely, advancements in AI offer valuable perspectives that deepen our understanding of biological neural processes. We believe that combining ideas from neuroscience and AI is essential to exploring new frontiers in both disciplines.",image:"/images/critical_artificial_nn.png"},{id:5,title:"motus med",shortDescription:"Transforming the epilepsy diagnostic pathway through accessible & intelligent movement analysis",fullDescription:i.a.createElement("div",null,i.a.createElement("a",{href:"https://motusmed.de"},"motus med")," is a video analysis-based digital health tool intended to assist in the diagnosis and monitoring of persons with abnormal movements, seizures, or epilepsy. Videos of suspected videos are uploaded to our platform, undergo automated analysis to detect movement patterns characteristic of seizures, and can be securely shared with a specialist for additional visual review. Through motus med, we apply several vision based AI models that we have developed in the lab.  Motus med integrates with a variety of smartphones and home cameras in order to provide a device agnostic, flexible, and scalable digital solution. The analysis results are provided to users to assist in decision-making during the diagnostic stage and for ongoing monitoring and management of disease activity in persons with epilepsy."),image:"/images/motusmed.png"},{id:6,title:"ALVEEG",shortDescription:"Ambulatory long-term video-EEG monitoring",fullDescription:i.a.createElement("div",null,i.a.createElement("a",{href:"https://www.alveeg.de"},"ALVEEG")," is a prospective, multicentre, randomized and controlled intervention study. In Germany, people with seizure disorders often have to wait months for a long-term video-EEG which is traditionally only performed in specialized hospitals. This can greatly delay the correct diagnosis and treatment. New sensor technologies and data analysis supported by artificial intelligence are opening up new diagnostic approaches. The aim of the project is to improve the care of people with seizure disorders by providing access to long-term video-EEGs in the home setting."),image:"/images/project_alveeg.jpg"},{id:7,title:"Medical Edge AI",shortDescription:"M/EDGE",fullDescription:"With their close integration of programmable microelectronics, sensors and actuators, modern medical devices have opened up fundamentally new diagnostic and therapeutic possibilities. These devices require integration of artificial intelligence and autonomy directly in the medical device, i.e. medical edge computing. Together with partners from academia, med tech and semiconductor industries, the M/EDGE project aims to develop an electronics platform for highly integrated medical edge artificial intelligence.",image:"/images/medge-logo.png"}];function u(e){let{project:a,isExpanded:t,onClick:n}=e;return i.a.createElement("div",{className:"project-card "+(t?"expanded":""),onClick:n},t?null:i.a.createElement("img",{src:a.image,alt:a.title}),i.a.createElement("h3",null,a.title),i.a.createElement("p",null,t?a.fullDescription:a.shortDescription),t?null:i.a.createElement("body",{className:"more-text"},"More..."))}var p=function(){const[e,a]=Object(n.useState)(null);return i.a.createElement("section",{id:"projects"},i.a.createElement("h2",{className:"section-title"},"Projects"),i.a.createElement("div",{className:"projects-container"},d.map(t=>i.a.createElement(u,{key:t.id,project:t,isExpanded:e===t.id,onClick:()=>{return n=t.id,void a(e===n?null:n);var n}}))))};t(44);const h=[{name:"Christian Meisel",role:"Principal Investigator",image:"images/team/christian.jpg",desc:""},{name:"Alexander Nelde",role:"PhD Student",image:"/images/team/alex.jpg",desc:""},{name:"Amrit Kashyap",role:"Postdoc",image:"/images/team/amrit.jpg",desc:""},{name:"Dominik D. Kranz",role:"PhD Student",image:"/images/team/dominik.jpg",desc:"I studied Biophysics and love interdisciplinary research. My interests include pretty much everything that's cool, new and shiny, but my specialty is applying and adapting neural network architectures for biosignal processing, with a focus on ECG and EEG analysis. I especially enjoy bringing these models to the clinic, where they can help improve patient care. "},{name:"Ela Marie Akay",role:"Medical Doctor",image:"images/team/ela_picture.jpg",desc:"As a neurology resident, I am interested in neurovascular medicine and using Artificial Intelligence to improve patient outcomes in neurocritical care and stroke medicine. In my research, I use routinely collected data for neurocritical and stroke unit patients to generate insights into different neurovascular pathologies. I am also fascinated by the broader implications of AI applications in everyday clinical practice and effects on neurological patients and the healthcare system at large."},{name:"Gadi Miron",role:"Medical Doctor",image:"/images/team/gadi.jpg",desc:i.a.createElement("div",null,"I am a neurologist and researcher with a special interest in epilepsy and digital health. My work focuses on understanding and addressing diagnostic challenges of people with epilepsy through computational analysis of EEG, imaging, and video data. Studies include AI-based video analysis of seizure semiology, retrospective clinical studies, EEG analysis for predicting seizures and long-term cognitive outcomes, and MRI analysis to better understand cognitive dysfunction in epilepsy. I also work to translate our research into clinical practice by developing a digital health tool, ",i.a.createElement("a",{href:"https://motusmed.de"},"https://motusmed.de"),", currently being tested at Charit\xe9 clinics.")},{name:"Jonas Stelzer",role:"Medical Student",image:"images/team/JonasS.jpg",desc:"Currently a medical student at Charit\xe9 University Hospital with a background in Economics from UCL, I am fascinated by the relationship between physiological cycles, such as heart rate variability, and brain states. By leveraging wearables, I am interested in bridging the gap between costly, hard-to-access brain activity data and consumer-grade health monitoring."},{name:"Laura Krumm",role:"PhD Student",image:"images/team/LauraK.png",desc:""},{name:"Lida Antonakopoulou",role:"Medical Doctor",image:"images/team/lidaA.png",desc:""},{name:"Maximilian Sch\xf6ls",role:"Medical Doctor",image:"images/team/Maximilian_Schoels.jpg",desc:""},{name:"Mustafa Halimeh",role:"PhD Student",image:"/images/team/Mustafa.jpg",desc:"Mustafa is a computer scientist working on data-driven pipelines to allow better long-term monitoring and treatment of neurological disorders. His current research involves applying state-of-the deep learning models and analytic tools on data recorded from wearables and videos to detect and predict seizures in epilepsy."},{name:"Paul M\xfcller",role:"Postdoc",image:"/images/team/paul.jpg",desc:"I am interested in cortical dynamics and their relation to cognitive function, especially in the context of epilepsy. Beyond my goal to improve our general understanding of cortical dynamics I aim to identify meaningful biomarkers for epilepsy management. My methods include neuronal, statistical and machine learning models, non-linear time series analysis within the framework of brain criticality, and the evaluation of behavioural testing."},{name:"Robert Terziev",role:"Medical Doctor",image:"/images/team/robert.jpg",desc:""},{name:"Simon Vock",role:"PhD Student",image:"images/team/SimonV.jpg",desc:"I am fascinated by the parallels between artificial neural networks and biological brains. My research focuses on critical phase transitions in machine learning, exploring how networks of simple units can give rise to complex, intelligent behavior. By applying insights from deep learning and physics, I study neural systems with the aim of advancing our understanding of both artificial and biological intelligence. Through this work, I hope to contribute to the development of more efficient AI systems and innovative treatments for neurological disorders."},{name:"Tim Wiegand",role:"Medical Doctor",image:"images/team/tim.png",desc:"I am a neurology resident at Charit\xe9 and a postdoctoral researcher in the computational neurology group. My doctoral thesis focused on advanced neuroimaging techniques in neurotrauma and neurodegenerative disease. Currently, my research centers on predictive modeling in neurology. More specifically, I am working on forecasting increases in intracranial pressure based on time-series data from the ICU. I am co-author of \u201cK\xfcnstliche Intelligenz in der Medizin\u201d, a textbook on AI in medicine."},{name:"Claudia Gorski",role:"Administration",image:"images/team/claudia.jpg",desc:""}];function g(e){let{member:a,isExpanded:t,onClick:n}=e;return i.a.createElement("div",{className:"team-card "+(t?"expanded":""),onClick:n},i.a.createElement("img",{src:a.image,alt:a.name}),i.a.createElement("h3",null,a.name),i.a.createElement("p",null,a.role),i.a.createElement("p",null,t?a.desc:""===a.desc?null:i.a.createElement("body",{className:"more-text"},"More...")))}var f=function(){const[e,a]=Object(n.useState)(null);return i.a.createElement("div",{className:"team-section-container"},i.a.createElement("section",{id:"team"},i.a.createElement("div",{className:"team-container-container"},i.a.createElement("h2",{className:"section-title team-title"},"Team"),i.a.createElement("div",{className:"team-container"},h.map(t=>i.a.createElement(g,{key:t.name,member:t,isExpanded:e===t.name,onClick:()=>{return n=t.name,void a(e===n?null:n);var n}}))))))};t(45);const y=["Amrit Kashyap","Jonas Stelzer","Paul M\xfcller","Gadi Miron","Lida Antonakopoulou","Agustina Aragon Daud","Lily Strittmatter","Mario Andina","Georg von Arnim"];function v(){return i.a.createElement("section",{id:"alumni"},i.a.createElement("h2",{className:"section-title"},"Alumni"),i.a.createElement("div",{className:"alumni-card"},i.a.createElement("img",{src:"/images/logo_group.webp",alt:"Lab logo",className:"alumni-logo"}),i.a.createElement("ul",{className:"alumni-list"},y.map(e=>i.a.createElement("li",{key:e},e)))))}var E=t(23),b=t.n(E);t(46);function w(e){if(!e)return"";let a=e;const t={"&":"&","\\%":"%","\\#":"#","\\$":"$","\\_":"_","\\{":"{","\\}":"}","\\~{}":" ","\\^{}":"^","\\textbf{":"","\\textit{":"","\\texttt{":"","}":"","{":"","\\ ":" "};Object.keys(t).forEach(e=>{const n=new RegExp(e,"g");a=a.replace(n,t[e])});const n={"\\'{a}":"\xe1","\\`{a}":"\xe0","\\~{a}":"\xe3","\\^{a}":"\xe2","\\.{a}":"a","\\'e":"\xe9","\\`e":"\xe8","\\~e":"\u1ebd","\\^e":"\xea","\\.e":"e"};return Object.keys(n).forEach(e=>{const t=new RegExp(e,"g");a=a.replace(t,n[e])}),a=a.replace(/\\[a-zA-Z]+\{([^}]+)\}/g,"$1"),a}var k=function(){const[e,a]=Object(n.useState)([]),[t,o]=Object(n.useState)(null),[r,l]=Object(n.useState)("");Object(n.useEffect)(()=>{(async()=>{try{const e=await fetch("/publications.bib?ts="+Date.now()),t=await e.text(),n=b.a.toJSON(t).map(e=>({id:e.citationKey,title:w(e.entryTags.title),authors:e.entryTags.author,journal:w(e.entryTags.journal),book:w(e.entryTags.booktitle),year:e.entryTags.year,doi:e.entryTags.doi,url:e.entryTags.url,abstract:w(e.entryTags.abstract),entryType:e.entryType,publisher:e.entryTags.publisher,volume:e.entryTags.volume,pages:e.entryTags.pages}));a(n)}catch(e){console.error("Error fetching or parsing BibTeX file:",e)}})()},[]);const s=e.reduce((e,a)=>{const t=a.year||"Unknown Year";return e[t]||(e[t]=[]),e[t].push(a),e},{}),c=Object.keys(s).sort((e,a)=>a-e);return i.a.createElement("section",{id:"publications"},i.a.createElement("h2",{className:"section-title"},"Publications"),c.map(e=>i.a.createElement("div",{key:e,className:"year-section"},i.a.createElement("h3",null,e),i.a.createElement("div",{className:"year-container"},s[e].map(e=>i.a.createElement("div",{key:e.id,className:"publication-card "+(t===e.id?"expanded":""),onClick:()=>{return a=e.id,void o(e=>e===a?null:a);var a}},i.a.createElement("h4",null,e.title),i.a.createElement("p",{style:{color:"grey",marginBottom:"20px",marginTop:"20px"}},e.authors),i.a.createElement("p",null,i.a.createElement("i",null,e.journal||"Preprint")),i.a.createElement("body",{className:"more-text"},t===e.id?"":"More..."),t===e.id&&i.a.createElement(i.a.Fragment,null,e.abstract&&i.a.createElement("p",null,i.a.createElement("strong",null,"Abstract:")," ",e.abstract),e.doi&&i.a.createElement("p",null,i.a.createElement("strong",null,"DOI:")," ",i.a.createElement("a",{href:"https://doi.org/"+e.doi,target:"_blank",rel:"noopener noreferrer"},e.doi)),e.url&&i.a.createElement("p",null,i.a.createElement("strong",null,"URL:")," ",i.a.createElement("a",{href:e.url,target:"_blank",rel:"noopener noreferrer"},"View Publication")))))))))};var N=function(){return i.a.createElement("div",{id:"footer"},i.a.createElement("footer",null,i.a.createElement("p",null,"Contact:"," ",i.a.createElement("a",{href:"mailto:computational-neurology@charite.de"},"computational-neurology at charite.de")),i.a.createElement("p",null,"\xa9 ",(new Date).getFullYear()," Computational Neurology Research Group")))};t(24),t(61),t(62),t(63),t(16);t(64);function T(){return i.a.createElement("section",{id:"competition-announcement"},i.a.createElement("h2",{className:"section-title"},"Video-Seizure Competition 2026"),i.a.createElement("div",{className:"competition-content"},i.a.createElement("p",null,"In partnership with The International Conference on Artificial Intelligence in Epilepsy and Other Neurological Disorders (2026), the Section on Computational Neurology at Charit\xe9 - Universit\xe4tsmedizin Berlin in Germany and partners are organizing a video-based seizure detection challenge."),i.a.createElement(l.b,{to:"/video_challenge",className:"competition-button"},"Details")))}t(65);function z(){return i.a.createElement("section",{id:"competition"},i.a.createElement("h2",{className:"section-title"},"Video-based Seizure Detection Challenge (2026)"),i.a.createElement("div",{className:"competition-intro"},i.a.createElement("p",null,"In partnership with ",i.a.createElement("strong",null,i.a.createElement("a",{href:"https://www.aiepilepsy-neuro.com/"},"The International Conference on Artificial Intelligence in Epilepsy and Other Neurological Disorders (2026)")),", the Section on Computational Neurology at Charit\xe9 \u2013 Universit\xe4tsmedizin Berlin and partners are organizing a video-based seizure detection challenge.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Key dates"),i.a.createElement("div",{className:"keydates"},i.a.createElement("div",{className:"k"},"Mid November 2025"),i.a.createElement("div",{className:"v"},"Challenge begins."),i.a.createElement("div",{className:"k"},"February 23, 2025"),i.a.createElement("div",{className:"v"},"Submission closes \u2014 submit early."),i.a.createElement("div",{className:"k"},"March 16\u201319, 2025"),i.a.createElement("div",{className:"v"},"Winners announced during the AI in Epilepsy 2026 conference."))),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Background"),i.a.createElement("p",null,"Epilepsy is a common neurological disorder affecting around 50 million people worldwide. Infantile epileptic spasm syndrome (IESS) is an early developmental and epileptic encephalopathy condition affecting approximately 1 in 2000-2500 infants in their first year of life. IESS is characterized by epileptic spasms which are sudden motor movements involving the head, arms, and legs. Despite the stereotypical nature of epileptic spasms, diagnosis is frequently delayed by weeks to months due to misidentification of symptoms as benign physiological occurrences or failure to recognize any abnormality by physicians or parents. These delays are associated with long-term poor cognitive outcomes, inadequate seizure control, increased disability, and higher healthcare costs. The widespread availability of smartphones and advancements in artificial intelligence (AI) may open new avenues for decision support in diagnosing these seizures [1].")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Objective"),i.a.createElement("p",null,"This challenge aims to build a video-based seizure detection model that detects if a ",i.a.createElement("strong",null,"5-second video segment")," contains an epileptic spasm or not. Video content is anonymized using a pose estimation algorithm. The pose estimation data includes a number of landmarks that represent key points on the skeleton of the child's body (further details below). Every 5-second segment contains 150 frames (fps=30), and pose estimation is performed on each frame. In this challenge, we are providing a training dataset to build the seizure detection models as a binary classification tast (video segment contains a seizure yes/no). The models will then be evaluated on large out-of-sample dataset.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Data description"),i.a.createElement("p",null,"The data includes 5-second video segments recorded from smartphones or other cameras from different children. Some of the children were diagnosed with infantile spasms. Each 5-second video segment may contain a seizure (at any time point) or could be normal, i.e., seizure-free. Across the training dataset, the same child may contribute multiple video segment from both classes or only from one class. To extract relevant movement while also preserving data privacy, we used the mediapipe library [2] to extract the pose landmarks from the children\u2019s video segments. The total number of landmarks is 33, and each landmark has 3 coordinates reflecting the position on the x, y, z axes, and two values (visibility and presence) referring to the degree of the presence of the landmark inside the frame scene. Note, that mediapipe may sometimes not extract the landmarks for some frames due to video quality issues. We used mediapipe version 0.10.21 with the model pose_landmarker_heavy.task.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Training data"),i.a.createElement("p",null,"The shared training data is a set of .npy files containing the landmarks from each frame of the respective 5-second segments (in total 150 frames corresponding to 30 frames per second (fps)). Missed frames have \u2018nan\u2019 landmarks. Besides the .npy files, there is a .csv file (comma \u2018,\u2019 separated) containing the true labels of those video segments along with their names (two columns; first column: segment_name (string), second column: label (int 0 or 1; 1 for seizure, 0 no seizure)."),i.a.createElement("p",null,"The .npy files have the following naming convention:"),i.a.createElement("code",null,"child_","{","id","}","_","{","segment","}"),i.a.createElement("p",null,"where ",i.a.createElement("code",null,"id")," and ",i.a.createElement("code",null,"segment")," are both integers. Segments belonging to the same child have the same ",i.a.createElement("code",null,"id"),". Here is an example of code to read the landmarks .npy file:"),i.a.createElement("div",{className:"codeblock"},i.a.createElement("pre",null,i.a.createElement("code",null,"import numpy as np\n\n# Read a .npy file containing video 5-second segments landmarks\nlmk_arr = np.load('child_1_1.npy')\n# lmk_arr.shape -> (150, 33, 5) -> (n_frames, n_landmarks, [x, y, z, visibility, presence])\n# lmk_arr.dtype -> float64\n\n# Get frames with nan landmarks\nis_nan = np.isnan(lmk_arr)\nnan_inx = np.any(is_nan, axis=(1, 2))\n"))),i.a.createElement("p",null,"Here is an example of code to read the .csv file:"),i.a.createElement("div",{className:"codeblock"},i.a.createElement("pre",null,i.a.createElement("code",null,"import pandas as pd\n\ntrain_df = pd.read_csv('train_data.csv', sep=',')\n\n# Example:\n# segment_name,label\n# child_1_1.npy,1\n# child_1_2.npy,0")))),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Output data"),i.a.createElement("p",null,"The prediction from each submitted model must be summarized in one single .csv file containing the predicted labels as 1 for seizure and 0 for non-seizure for each 5-second video segment (.npy file) along with the file name. Thus, the output .csv file must have only two columns (first column: file name, second column: label). Please note that the predicted labels are required per each 5-second video segment and not per each child, so participants must not predict if a child has infantile spasms or not.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Performance metrics"),i.a.createElement("p",null,"Based on the predicted labels from each participant\u2019s model, we will compute the performance metrics of sensitivity, specificity, accuracy, and F1-score using an out-of-sample test dataset. These metrics will be computed as sample-based, i.e., each 5-second video segment will have a single prediction value of either 1 or 0. We will report the metrics as follows:"),i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("strong",null,"Sensitivity"),": TP / (TP + FN)"),i.a.createElement("li",null,i.a.createElement("strong",null,"Specificity"),": TN / (TN + FP)"),i.a.createElement("li",null,i.a.createElement("strong",null,"Precision"),": TP / (TP + FP)"),i.a.createElement("li",null,i.a.createElement("strong",null,"F1-score"),": 2 \xd7 (Precision \xd7 Sensitivity) / (Precision + Sensitivity)"))),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Evaluation"),i.a.createElement("p",null,"Submissions will be evaluated on an out-of-sample dataset using the above defined performance metrics. The F1 score will be used as a main metric to rank the performances and, in case of tie of F1 score values, sensitivity will be considered as a secondary ranking metric.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Awards"),i.a.createElement("p",null,"Our sponsors are generously offering $10,000 prizes for the winning participants. This prize money will be split among only the best two algorithms as follows:"),i.a.createElement("ul",{className:"awards"},i.a.createElement("li",null,i.a.createElement("strong",null,"#1:")," $7,000"),i.a.createElement("li",null,i.a.createElement("strong",null,"#2:")," $3,000")),i.a.createElement("p",null,"Both winning participant teams (first/second place) are required to send their detailed solutions with the source code for final verification. This will demand them to agree on sharing their code under a CC-BY- SA 4.0 license to receive the full awarded prize money."),i.a.createElement("p",null,"The challenge organizers will write a summary of the outcome of the challenge in a leading journal in our field. The top challenge contributors will be invited to contribute to this paper to describe their methodology.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Organizers"),i.a.createElement("p",null,"The challenge is organized by the Section on Computational Neurology at Charit\xe9 - Universit\xe4tsmedizin Berlin in Germany, in collaboration with sponsor1, sponsor2 and sponsor3. For questions to the organizers, you can contact Christian Meisel or Mustafa Halimeh: ",i.a.createElement("a",{href:"mailto:computational-neurology@charite.de"},"computational-neurology@charite.de"))),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Legal statement"),i.a.createElement("p",null,"Participants must acknowledge that the shared data must only be used for this competition.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Submission guidelines"),"Participants should provide a pre-trained model packaged as a Docker image. The Docker image should be downloadable from an image registry. Participants can have a maximum of three different submissions. An abstract describing the methodology and performance of the training data is optional. Participants are invited to submit a poster in addition to the challenge submission, more details on poster submission are available on the ",i.a.createElement("a",{href:"https://www.aiepilepsy-neuro.com/"}," AI in epilepsy conference website"),".",i.a.createElement("p",null,i.a.createElement("strong",null,"Docker requirements:")),i.a.createElement("p",null,"The docker image must contain two volumes, and define two environment variables:"),i.a.createElement("div",{className:"codeblock"},i.a.createElement("pre",null,i.a.createElement("code",null,'VOLUME ["/data"]\nVOLUME ["/output"]\nENV INPUT=""\nENV OUTPUT=""'))),i.a.createElement("p",null,"Where ",i.a.createElement("code",null,"INPUT")," and ",i.a.createElement("code",null,"OUTPUT")," variables contain the path to test-out dataset and .csv file relative to /data and /output.")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Computing platform"),i.a.createElement("p",null,"We will run all submitted models and algorithms on our HPC on premises. The device will have no internet access during the evaluation of the submissions. The computer is a DELL workstation with 2 Nvidia RTX 6000 GPUs, 32 CPU cores, and 48 GB RAM memory in each GPU. Windows 11 is the main OS but also Linux Subsystem is included (WSL ubuntu).")),i.a.createElement("div",{className:"competition-card"},i.a.createElement("h3",null,"Submission form"),i.a.createElement("p",{className:"smallprint"},"Please submit your algorithms via submission form (link below). The algorithms submitted here remain the strict property of the inventor. Neither the conference organizers nor the challenge sponsors have any intellectual property claims on the algorithms. The conference organizers will not share or disseminate them after the evaluation of the model. They will use the algorithms during the challenge to evaluate performance on a holdout dataset. To be eligible to receive the prize money, at least one co-author of the submitted model must be registered (in person or virtual) for the conference. Teams that are not registered can participate, but they will not be eligible to win.")),i.a.createElement("a",{href:"https://forms.office.com/Pages/ResponsePage.aspx?id=ORnprz6SLEO8ZsvD7BjQLE1mFpKUXcBDnOuOUqQLSWVUREQ5WEJLVUdFQkE5VTVENVhCUjNJQ0NITCQlQCN0PWcu",target:"_blank",rel:"noopener noreferrer",className:"competition-button"},"Submit your entry"),i.a.createElement("div",{className:"refs"},i.a.createElement("h4",null,"References"),i.a.createElement("ol",null,i.a.createElement("li",null,"Miron, G., Halimeh, M., Tietze, S. et al. Detection of epileptic spasms using foundational AI and smartphone videos. npj Digit. Med. 8, 370 (2025). https://doi.org/10.1038/s41746-025-01773-1"),i.a.createElement("li",null,"Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., Zhang, F., Chang, C., Yong, M.G., Lee, J., Chang, W., Hua, W., Georg, M., & Grundmann, M. (2019). MediaPipe: A Framework for Building Perception Pipelines. https://doi.org/10.48550/arXiv.1906.08172"))))}var C=function(){return i.a.createElement(l.a,null,i.a.createElement("div",{className:"App"},i.a.createElement(m,null),i.a.createElement(s.c,null,i.a.createElement(s.a,{path:"/",element:i.a.createElement("main",null,i.a.createElement(T,null),i.a.createElement(p,null),i.a.createElement(f,null),i.a.createElement(v,null),i.a.createElement(k,null))}),i.a.createElement(s.a,{path:"/video_challenge",element:i.a.createElement(z,null)})),i.a.createElement(N,null)))};var D=e=>{e&&e instanceof Function&&t.e(3).then(t.bind(null,68)).then(a=>{let{getCLS:t,getFID:n,getFCP:i,getLCP:o,getTTFB:r}=a;t(e),n(e),i(e),o(e),r(e)})};t(66);r.a.createRoot(document.getElementById("root")).render(i.a.createElement(i.a.StrictMode,null,i.a.createElement(C,null))),D()}},[[25,1,2]]]);
//# sourceMappingURL=main.9796c595.chunk.js.map